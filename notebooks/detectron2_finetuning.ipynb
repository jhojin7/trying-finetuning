{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detectron2 Fine-tuning for Electronic Components Detection\n",
    "\n",
    "This notebook demonstrates fine-tuning a pre-trained Detectron2 model on the electronic components dataset for pre-labeling workflow.\n",
    "\n",
    "**Goal**: Train a model that can pre-label new images, allowing human labelers to focus on minor corrections rather than full annotation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Detectron2 imports\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "print(f\"Detectron2 version: {detectron2.__version__}\")\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Register COCO Dataset\n",
    "\n",
    "Register the electronic components dataset in COCO format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths\n",
    "DATA_ROOT = \"../dataset\"\n",
    "TRAIN_JSON = os.path.join(DATA_ROOT, \"train/_annotations.coco.json\")\n",
    "TRAIN_DIR = os.path.join(DATA_ROOT, \"train\")\n",
    "VAL_JSON = os.path.join(DATA_ROOT, \"valid/_annotations.coco.json\")\n",
    "VAL_DIR = os.path.join(DATA_ROOT, \"valid\")\n",
    "TEST_JSON = os.path.join(DATA_ROOT, \"test/_annotations.coco.json\")\n",
    "TEST_DIR = os.path.join(DATA_ROOT, \"test\")\n",
    "\n",
    "# Register datasets\n",
    "register_coco_instances(\"electronics_train\", {}, TRAIN_JSON, TRAIN_DIR)\n",
    "register_coco_instances(\"electronics_val\", {}, VAL_JSON, VAL_DIR)\n",
    "register_coco_instances(\"electronics_test\", {}, TEST_JSON, TEST_DIR)\n",
    "\n",
    "# Get metadata\n",
    "metadata = MetadataCatalog.get(\"electronics_train\")\n",
    "dataset_dicts = DatasetCatalog.get(\"electronics_train\")\n",
    "\n",
    "print(f\"Number of training images: {len(dataset_dicts)}\")\n",
    "print(f\"Categories: {metadata.thing_classes}\")\n",
    "print(f\"Number of categories: {len(metadata.thing_classes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Sample Data\n",
    "\n",
    "Let's visualize a few samples from the training set to verify the data is loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize random samples\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    d = random.choice(dataset_dicts)\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, scale=0.5)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    ax.imshow(out.get_image())\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f\"Sample {i+1}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/predictions/training_samples.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Sample visualization saved to outputs/predictions/training_samples.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configure Model\n",
    "\n",
    "Using Faster R-CNN with ResNet-50 FPN backbone. This is a good balance between speed and accuracy for quick training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "\n",
    "# Load pre-trained model from model zoo\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
    "\n",
    "# Dataset configuration\n",
    "cfg.DATASETS.TRAIN = (\"electronics_train\",)\n",
    "cfg.DATASETS.TEST = (\"electronics_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "\n",
    "# Training configuration - optimized for quick demo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # Learning rate\n",
    "cfg.SOLVER.MAX_ITER = 500     # Quick training for demo (increase to 2000+ for better results)\n",
    "cfg.SOLVER.STEPS = (300, 450)  # Learning rate decay steps\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 250  # Save checkpoint every N iterations\n",
    "\n",
    "# Model configuration\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(metadata.thing_classes)\n",
    "\n",
    "# Output directory\n",
    "cfg.OUTPUT_DIR = \"../outputs/models\"\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Use MPS (Metal Performance Shaders) for Mac GPU acceleration if available\n",
    "# Detectron2 may not support MPS directly, so it will fall back to CPU\n",
    "# cfg.MODEL.DEVICE = \"mps\"  # Uncomment if MPS is supported\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Model: Faster R-CNN R50-FPN\")\n",
    "print(f\"  Number of classes: {cfg.MODEL.ROI_HEADS.NUM_CLASSES}\")\n",
    "print(f\"  Max iterations: {cfg.SOLVER.MAX_ITER}\")\n",
    "print(f\"  Learning rate: {cfg.SOLVER.BASE_LR}\")\n",
    "print(f\"  Output directory: {cfg.OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train the Model\n",
    "\n",
    "This will run for ~500 iterations. On Mac Studio, this should take 1-2 hours.\n",
    "\n",
    "**Note**: You can monitor the training progress in the output. Loss values should decrease over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer and start training\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "\n",
    "print(f\"\\nðŸš€ Starting training at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Training for {cfg.SOLVER.MAX_ITER} iterations...\\n\")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(f\"\\nâœ… Training complete at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Model saved to: {cfg.OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate on Validation Set\n",
    "\n",
    "Let's see how well the model performs on unseen validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure for inference\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Set confidence threshold\n",
    "\n",
    "# Evaluate on validation set\n",
    "evaluator = COCOEvaluator(\"electronics_val\", output_dir=cfg.OUTPUT_DIR)\n",
    "val_loader = build_detection_test_loader(cfg, \"electronics_val\")\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "print(\"Running evaluation on validation set...\")\n",
    "results = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Predictions on Sample Images\n",
    "\n",
    "Let's visualize predictions on some test images to see the model in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test dataset\n",
    "test_dataset_dicts = DatasetCatalog.get(\"electronics_test\")\n",
    "test_metadata = MetadataCatalog.get(\"electronics_test\")\n",
    "\n",
    "# Visualize predictions on random test images\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    d = random.choice(test_dataset_dicts)\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(img)\n",
    "    \n",
    "    v = Visualizer(img[:, :, ::-1],\n",
    "                   metadata=test_metadata,\n",
    "                   scale=0.5,\n",
    "                   instance_mode=ColorMode.IMAGE)\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    \n",
    "    ax.imshow(out.get_image())\n",
    "    ax.axis('off')\n",
    "    num_detections = len(outputs[\"instances\"])\n",
    "    ax.set_title(f\"Test Sample {i+1}\\n({num_detections} detections)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/predictions/test_predictions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Test predictions saved to outputs/predictions/test_predictions.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Before/After Comparison\n",
    "\n",
    "Compare the pre-trained COCO model (before fine-tuning) vs. our fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictor with pre-trained COCO weights (before fine-tuning)\n",
    "cfg_before = get_cfg()\n",
    "cfg_before.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg_before.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg_before.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "predictor_before = DefaultPredictor(cfg_before)\n",
    "\n",
    "# Pick a test image\n",
    "test_img_dict = random.choice(test_dataset_dicts)\n",
    "test_img = cv2.imread(test_img_dict[\"file_name\"])\n",
    "\n",
    "# Before: Pre-trained COCO model\n",
    "outputs_before = predictor_before(test_img)\n",
    "v_before = Visualizer(test_img[:, :, ::-1],\n",
    "                      metadata=MetadataCatalog.get(cfg_before.DATASETS.TRAIN[0]),\n",
    "                      scale=0.8)\n",
    "out_before = v_before.draw_instance_predictions(outputs_before[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "# After: Fine-tuned model\n",
    "outputs_after = predictor(test_img)\n",
    "v_after = Visualizer(test_img[:, :, ::-1],\n",
    "                     metadata=test_metadata,\n",
    "                     scale=0.8,\n",
    "                     instance_mode=ColorMode.IMAGE)\n",
    "out_after = v_after.draw_instance_predictions(outputs_after[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "# Display side-by-side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "axes[0].imshow(out_before.get_image())\n",
    "axes[0].set_title(f\"BEFORE: Pre-trained COCO Model\\n({len(outputs_before['instances'])} detections)\", fontsize=14)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(out_after.get_image())\n",
    "axes[1].set_title(f\"AFTER: Fine-tuned Model\\n({len(outputs_after['instances'])} detections)\", fontsize=14)\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/predictions/before_after_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Before/after comparison saved to outputs/predictions/before_after_comparison.png\")\n",
    "print(\"\\nðŸ“Š This visualization shows the improvement from fine-tuning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "Training complete! You now have:\n",
    "\n",
    "1. **Fine-tuned model** saved in `outputs/models/model_final.pth`\n",
    "2. **Visualizations** showing:\n",
    "   - Training samples\n",
    "   - Test predictions\n",
    "   - Before/after comparison\n",
    "3. **Evaluation metrics** on validation set\n",
    "\n",
    "### Next Steps for Production:\n",
    "1. **Increase training iterations** to 2000-3000 for better results\n",
    "2. **Tune hyperparameters** (learning rate, batch size, etc.)\n",
    "3. **Use the inference script** (`scripts/predict.py`) for batch pre-labeling\n",
    "4. **Integrate with CVAT or FiftyOne** for human review workflow\n",
    "\n",
    "For batch pre-labeling, run:\n",
    "```bash\n",
    "python scripts/predict.py --input /path/to/new/images --output /path/to/predictions\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸŽ‰ DEMO READY FOR TOMORROW!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nModel location: {cfg.OUTPUT_DIR}/model_final.pth\")\n",
    "print(f\"Visualizations: ../outputs/predictions/\")\n",
    "print(f\"\\nTotal training iterations: {cfg.SOLVER.MAX_ITER}\")\n",
    "print(f\"Number of classes: {cfg.MODEL.ROI_HEADS.NUM_CLASSES}\")\n",
    "print(\"\\nReady to demonstrate pre-labeling workflow!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
