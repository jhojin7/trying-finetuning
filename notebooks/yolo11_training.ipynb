{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Train YOLO11 Models\n",
    "\n",
    "**Based on:** [EdjeElectronics YOLO Training Tutorial](https://youtu.be/r0RspiLG260)\n",
    "\n",
    "**GitHub:** [Train and Deploy YOLO Models](https://github.com/EdjeElectronics/Train-and-Deploy-YOLO-Models)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook uses [Ultralytics](https://docs.ultralytics.com/) to train YOLO11 object detection models with a custom dataset. At the end of this notebook, you'll have a custom YOLO model ready for deployment.\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "1. How to prepare datasets in YOLO format\n",
    "2. How to train YOLO11 models\n",
    "3. How to validate and test your trained models\n",
    "4. How to deploy models for inference\n",
    "\n",
    "### Dataset Options\n",
    "\n",
    "You can use:\n",
    "- **Your own custom dataset** (recommended for best results)\n",
    "- **Pre-made datasets** like candy detection or coin detection\n",
    "- **Roboflow Universe datasets**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import random\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Check if we're in a notebook subdirectory\n",
    "if Path.cwd().name == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install",
   "metadata": {},
   "source": [
    "## 2. Install Ultralytics\n",
    "\n",
    "Install the Ultralytics library which provides YOLO11, YOLOv8, and YOLOv5 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install_ultralytics",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q ultralytics\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Installation Complete!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset_prep",
   "metadata": {},
   "source": [
    "## 3. Prepare Dataset\n",
    "\n",
    "### Dataset Structure\n",
    "\n",
    "YOLO requires the following folder structure:\n",
    "\n",
    "```\n",
    "custom_data/\n",
    "‚îú‚îÄ‚îÄ images/          # Your images (JPG or PNG)\n",
    "‚îú‚îÄ‚îÄ labels/          # YOLO format labels (.txt)\n",
    "‚îî‚îÄ‚îÄ classes.txt      # List of class names (one per line)\n",
    "```\n",
    "\n",
    "### Label Format\n",
    "\n",
    "Each `.txt` label file contains one line per object:\n",
    "```\n",
    "<class_id> <x_center> <y_center> <width> <height>\n",
    "```\n",
    "All values are normalized (0-1) relative to image dimensions.\n",
    "\n",
    "### Options for Getting Data\n",
    "\n",
    "**Option 1:** Use your own custom dataset (place it in `custom_data/` folder)\n",
    "\n",
    "**Option 2:** Download a pre-made dataset (uncomment one of the commands below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download_dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Download pre-made dataset\n",
    "# Uncomment ONE of the following lines:\n",
    "\n",
    "# Candy detection dataset (162 images)\n",
    "# !wget -O data.zip https://s3.us-west-1.amazonaws.com/evanjuras.com/resources/candy_data_06JAN25.zip\n",
    "\n",
    "# Coin detection dataset (750 images)\n",
    "# !wget -O data.zip https://s3.us-west-1.amazonaws.com/evanjuras.com/resources/YOLO_coin_data_12DEC30.zip\n",
    "\n",
    "# If you downloaded a dataset, unzip it:\n",
    "# !unzip -q data.zip -d custom_data\n",
    "\n",
    "print(\"If you're using your own dataset, make sure it's in the custom_data/ folder!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split_dataset",
   "metadata": {},
   "source": [
    "## 4. Split Dataset into Train and Validation\n",
    "\n",
    "We'll split the dataset into 90% training and 10% validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_val_split",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(datapath, train_pct=0.9):\n",
    "    \"\"\"\n",
    "    Split dataset into train and validation folders.\n",
    "    \n",
    "    Args:\n",
    "        datapath: Path to custom_data folder containing images/ and labels/\n",
    "        train_pct: Percentage of data to use for training (default 0.9)\n",
    "    \"\"\"\n",
    "    datapath = Path(datapath)\n",
    "    images_dir = datapath / 'images'\n",
    "    labels_dir = datapath / 'labels'\n",
    "    \n",
    "    if not images_dir.exists():\n",
    "        print(f\"‚ùå Error: {images_dir} does not exist!\")\n",
    "        return\n",
    "    \n",
    "    # Create output directories\n",
    "    data_root = Path('data')\n",
    "    for split in ['train', 'validation']:\n",
    "        (data_root / split / 'images').mkdir(parents=True, exist_ok=True)\n",
    "        (data_root / split / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Get all image files\n",
    "    image_files = list(images_dir.glob('*.jpg')) + list(images_dir.glob('*.png')) + list(images_dir.glob('*.jpeg'))\n",
    "    print(f\"Found {len(image_files)} images\")\n",
    "    \n",
    "    # Shuffle and split\n",
    "    random.shuffle(image_files)\n",
    "    split_idx = int(len(image_files) * train_pct)\n",
    "    train_files = image_files[:split_idx]\n",
    "    val_files = image_files[split_idx:]\n",
    "    \n",
    "    print(f\"Train: {len(train_files)} images\")\n",
    "    print(f\"Validation: {len(val_files)} images\")\n",
    "    \n",
    "    # Copy files\n",
    "    for file_list, split in [(train_files, 'train'), (val_files, 'validation')]:\n",
    "        for img_file in file_list:\n",
    "            # Copy image\n",
    "            shutil.copy2(img_file, data_root / split / 'images' / img_file.name)\n",
    "            \n",
    "            # Copy corresponding label\n",
    "            label_file = labels_dir / f\"{img_file.stem}.txt\"\n",
    "            if label_file.exists():\n",
    "                shutil.copy2(label_file, data_root / split / 'labels' / label_file.name)\n",
    "    \n",
    "    print(\"\\n‚úÖ Dataset split complete!\")\n",
    "    print(f\"Output directory: {data_root.absolute()}\")\n",
    "\n",
    "# Run the split\n",
    "train_val_split('custom_data', train_pct=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize",
   "metadata": {},
   "source": [
    "## 5. Visualize Training Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz_samples",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_yolo_sample(image_path, label_path, class_names):\n",
    "    \"\"\"\n",
    "    Visualize a single YOLO training sample.\n",
    "    \"\"\"\n",
    "    # Read image\n",
    "    image = cv2.imread(str(image_path))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    # Read labels\n",
    "    if label_path.exists():\n",
    "        with open(label_path, 'r') as f:\n",
    "            labels = f.readlines()\n",
    "        \n",
    "        # Draw bounding boxes\n",
    "        for label in labels:\n",
    "            parts = label.strip().split()\n",
    "            if len(parts) == 5:\n",
    "                class_id = int(parts[0])\n",
    "                x_center, y_center, width, height = map(float, parts[1:])\n",
    "                \n",
    "                # Convert normalized coordinates to pixel coordinates\n",
    "                x_center *= w\n",
    "                y_center *= h\n",
    "                width *= w\n",
    "                height *= h\n",
    "                \n",
    "                # Calculate box corners\n",
    "                x1 = int(x_center - width / 2)\n",
    "                y1 = int(y_center - height / 2)\n",
    "                x2 = int(x_center + width / 2)\n",
    "                y2 = int(y_center + height / 2)\n",
    "                \n",
    "                # Draw box\n",
    "                color = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "                cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "                \n",
    "                # Add label\n",
    "                label_text = class_names[class_id] if class_id < len(class_names) else f\"Class {class_id}\"\n",
    "                cv2.putText(image, label_text, (x1, y1 - 10),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Load class names\n",
    "classes_file = Path('custom_data/classes.txt')\n",
    "if classes_file.exists():\n",
    "    with open(classes_file, 'r') as f:\n",
    "        class_names = [line.strip() for line in f.readlines() if line.strip()]\n",
    "    \n",
    "    print(f\"Classes: {class_names}\\n\")\n",
    "    \n",
    "    # Visualize a few samples\n",
    "    train_images_dir = Path('data/train/images')\n",
    "    train_labels_dir = Path('data/train/labels')\n",
    "    \n",
    "    if train_images_dir.exists():\n",
    "        image_files = list(train_images_dir.glob('*.jpg')) + list(train_images_dir.glob('*.png'))\n",
    "        \n",
    "        # Show 6 random samples\n",
    "        num_samples = min(6, len(image_files))\n",
    "        sample_indices = np.random.choice(len(image_files), num_samples, replace=False)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for idx, sample_idx in enumerate(sample_indices):\n",
    "            img_path = image_files[sample_idx]\n",
    "            label_path = train_labels_dir / f\"{img_path.stem}.txt\"\n",
    "            \n",
    "            img = visualize_yolo_sample(img_path, label_path, class_names)\n",
    "            \n",
    "            axes[idx].imshow(img)\n",
    "            axes[idx].axis('off')\n",
    "            axes[idx].set_title(f\"{img_path.name}\", fontsize=8)\n",
    "        \n",
    "        plt.suptitle('Training Samples with Annotations', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è classes.txt not found. Please create it in custom_data/classes.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create_yaml",
   "metadata": {},
   "source": [
    "## 6. Create YOLO Configuration File\n",
    "\n",
    "Create a `data.yaml` file that tells YOLO where to find the training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate_yaml",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_yaml(path_to_classes_txt, path_to_data_yaml):\n",
    "    \"\"\"\n",
    "    Create YOLO data.yaml configuration file.\n",
    "    \"\"\"\n",
    "    # Read classes\n",
    "    if not os.path.exists(path_to_classes_txt):\n",
    "        print(f'‚ùå classes.txt not found at {path_to_classes_txt}')\n",
    "        print('Please create a classes.txt file with one class name per line.')\n",
    "        return\n",
    "    \n",
    "    with open(path_to_classes_txt, 'r') as f:\n",
    "        classes = [line.strip() for line in f.readlines() if line.strip()]\n",
    "    \n",
    "    num_classes = len(classes)\n",
    "    \n",
    "    # Create data dictionary\n",
    "    data = {\n",
    "        'path': str(Path('data').absolute()),\n",
    "        'train': 'train/images',\n",
    "        'val': 'validation/images',\n",
    "        'nc': num_classes,\n",
    "        'names': classes\n",
    "    }\n",
    "    \n",
    "    # Write YAML file\n",
    "    with open(path_to_data_yaml, 'w') as f:\n",
    "        yaml.dump(data, f, sort_keys=False)\n",
    "    \n",
    "    print(f'‚úÖ Created config file at {path_to_data_yaml}')\n",
    "    print(f'\\nNumber of classes: {num_classes}')\n",
    "    print(f'Classes: {classes}')\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Create the YAML file\n",
    "classes_txt_path = 'custom_data/classes.txt'\n",
    "data_yaml_path = 'data.yaml'\n",
    "\n",
    "config = create_data_yaml(classes_txt_path, data_yaml_path)\n",
    "\n",
    "print('\\nüìÑ Configuration file contents:\\n')\n",
    "!cat data.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training_config",
   "metadata": {},
   "source": [
    "## 7. Configure Training Parameters\n",
    "\n",
    "### Key Parameters:\n",
    "\n",
    "**Model Size (`model`):**\n",
    "- `yolo11n.pt` - Nano (fastest, lowest accuracy)\n",
    "- `yolo11s.pt` - Small (good balance) ‚≠ê **Recommended for starting**\n",
    "- `yolo11m.pt` - Medium\n",
    "- `yolo11l.pt` - Large\n",
    "- `yolo11x.pt` - Extra Large (slowest, highest accuracy)\n",
    "\n",
    "**Epochs:**\n",
    "- Small dataset (<200 images): 60 epochs\n",
    "- Large dataset (>200 images): 40 epochs\n",
    "\n",
    "**Image Size (`imgsz`):**\n",
    "- Standard: 640x640\n",
    "- Faster/Lower resolution: 480x480\n",
    "- Higher accuracy: 1280x1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training_params",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "TRAINING_CONFIG = {\n",
    "    'data': 'data.yaml',          # Path to data config\n",
    "    'model': 'yolo11s.pt',        # Model size\n",
    "    'epochs': 60,                 # Number of training epochs\n",
    "    'imgsz': 640,                 # Image size\n",
    "    'batch': -1,                  # Batch size (-1 for auto)\n",
    "    'device': 0 if torch.cuda.is_available() else 'cpu',  # Use GPU if available\n",
    "    'project': 'runs/detect',     # Project directory\n",
    "    'name': 'train',              # Experiment name\n",
    "    'exist_ok': True,             # Overwrite existing\n",
    "    'patience': 50,               # Early stopping patience\n",
    "    'save': True,                 # Save checkpoints\n",
    "    'plots': True,                # Save training plots\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    print(f\"  {key:15s}: {value}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train",
   "metadata": {},
   "source": [
    "## 8. Train the Model\n",
    "\n",
    "This will download the pre-trained YOLO11 model and fine-tune it on your custom dataset.\n",
    "\n",
    "**Note:** Training will take some time depending on your hardware:\n",
    "- GPU: ~10-30 minutes\n",
    "- CPU: ~1-3 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = YOLO(TRAINING_CONFIG['model'])\n",
    "\n",
    "print(\"\\nüöÄ Starting training...\\n\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(**TRAINING_CONFIG)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Training Complete!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBest model saved at: runs/detect/train/weights/best.pt\")\n",
    "print(f\"Training plots saved at: runs/detect/train/results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize_results",
   "metadata": {},
   "source": [
    "## 9. Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "show_results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training results\n",
    "results_plot = Path('runs/detect/train/results.png')\n",
    "if results_plot.exists():\n",
    "    img = plt.imread(str(results_plot))\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Training Results', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Results plot not found\")\n",
    "\n",
    "# Display confusion matrix\n",
    "confusion_matrix = Path('runs/detect/train/confusion_matrix.png')\n",
    "if confusion_matrix.exists():\n",
    "    img = plt.imread(str(confusion_matrix))\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Confusion Matrix', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Confusion matrix not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validate",
   "metadata": {},
   "source": [
    "## 10. Validate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model_path = 'runs/detect/train/weights/best.pt'\n",
    "model = YOLO(best_model_path)\n",
    "\n",
    "print(\"Running validation...\\n\")\n",
    "\n",
    "# Validate\n",
    "metrics = model.val(data='data.yaml')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Validation Metrics:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"mAP50:     {metrics.box.map50:.4f} ({metrics.box.map50*100:.2f}%)\")\n",
    "print(f\"mAP50-95:  {metrics.box.map:.4f} ({metrics.box.map*100:.2f}%)\")\n",
    "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall:    {metrics.box.mr:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test",
   "metadata": {},
   "source": [
    "## 11. Test Model on Validation Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run predictions on validation images\n",
    "val_images_path = 'data/validation/images'\n",
    "predict_results = model.predict(\n",
    "    source=val_images_path,\n",
    "    conf=0.25,\n",
    "    save=True,\n",
    "    project='runs/detect',\n",
    "    name='predict',\n",
    "    exist_ok=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Predictions saved to: runs/detect/predict/\")\n",
    "\n",
    "# Display first 10 predictions\n",
    "import glob\n",
    "from IPython.display import Image as IPImage, display\n",
    "\n",
    "pred_images = glob.glob('runs/detect/predict/*.jpg')[:10]\n",
    "\n",
    "if pred_images:\n",
    "    print(f\"\\nShowing first {len(pred_images)} predictions:\\n\")\n",
    "    for img_path in pred_images:\n",
    "        display(IPImage(filename=img_path, width=600))\n",
    "        print('\\n')\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No predictions found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export",
   "metadata": {},
   "source": [
    "## 12. Export Model\n",
    "\n",
    "Export the model to different formats for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to ONNX format (most common)\n",
    "print(\"Exporting model to ONNX format...\")\n",
    "onnx_path = model.export(format='onnx', dynamic=True)\n",
    "print(f\"‚úÖ ONNX model exported to: {onnx_path}\")\n",
    "\n",
    "# Uncomment to export to other formats:\n",
    "# coreml_path = model.export(format='coreml')  # For iOS/macOS\n",
    "# tflite_path = model.export(format='tflite')  # For mobile/edge devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inference",
   "metadata": {},
   "source": [
    "## 13. Run Inference on Custom Images\n",
    "\n",
    "Test your model on any image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom_inference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Run on a single image\n",
    "# Replace 'path/to/your/image.jpg' with your image path\n",
    "\n",
    "# test_image = 'path/to/your/image.jpg'\n",
    "# results = model.predict(test_image, conf=0.25, save=True)\n",
    "\n",
    "# # Display results\n",
    "# for result in results:\n",
    "#     boxes = result.boxes\n",
    "#     print(f\"Detected {len(boxes)} objects\")\n",
    "#     for box in boxes:\n",
    "#         class_id = int(box.cls[0])\n",
    "#         confidence = float(box.conf[0])\n",
    "#         class_name = model.names[class_id]\n",
    "#         print(f\"  - {class_name}: {confidence:.2f}\")\n",
    "\n",
    "print(\"Uncomment the code above and replace the image path to test!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## 14. Summary\n",
    "\n",
    "### üéâ Congratulations!\n",
    "\n",
    "You've successfully trained a YOLO11 object detection model!\n",
    "\n",
    "### üìÅ Key Files:\n",
    "\n",
    "- **Best model:** `runs/detect/train/weights/best.pt`\n",
    "- **Last checkpoint:** `runs/detect/train/weights/last.pt`\n",
    "- **Training plots:** `runs/detect/train/results.png`\n",
    "- **Predictions:** `runs/detect/predict/`\n",
    "- **ONNX model:** `runs/detect/train/weights/best.onnx`\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "\n",
    "1. **Deploy on PC/Mac:**\n",
    "   ```python\n",
    "   from ultralytics import YOLO\n",
    "   model = YOLO('runs/detect/train/weights/best.pt')\n",
    "   results = model.predict('image.jpg')\n",
    "   ```\n",
    "\n",
    "2. **Deploy on Raspberry Pi:**\n",
    "   - Convert to NCNN or TFLite format\n",
    "   - Use Ultralytics CLI or Python API\n",
    "\n",
    "3. **Improve Model:**\n",
    "   - Add more training images\n",
    "   - Increase epochs\n",
    "   - Use larger model (yolo11m or yolo11l)\n",
    "   - Tune hyperparameters\n",
    "\n",
    "### üìö Resources:\n",
    "\n",
    "- [Ultralytics Documentation](https://docs.ultralytics.com/)\n",
    "- [YOLO GitHub](https://github.com/ultralytics/ultralytics)\n",
    "- [EdjeElectronics Tutorial](https://github.com/EdjeElectronics/Train-and-Deploy-YOLO-Models)\n",
    "\n",
    "---\n",
    "\n",
    "**Happy detecting!** üéØ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
